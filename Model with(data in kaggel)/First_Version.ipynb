{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lumfGxY6P8zB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ9Bdq81kf0h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiWpUHbJbs4G"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNSJEnLah6W5"
      },
      "source": [
        "# **Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ttibo3Xh6XK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install tensorflow\n",
        "%pip install keras\n",
        "%pip install netron\n",
        "%pip install nltk\n",
        "\n",
        "#%pip3 install git+https://github.com/huggingface/transformers\n",
        "%pip install datasets\n",
        "%pip install nlp\n",
        "%pip install rouge-score\n",
        "!pip install sacrebleu\n",
        "%pip install git-python\n",
        "%pip install sentencepiece\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "%pip install tree-sitter\n",
        "%pip install evaluate\n",
        "%pip install datasets\n",
        "%pip install sentencepiece\n",
        "%pip install rouge_score\n",
        "%pip install sacremoses\n",
        "%pip install torchdata\n",
        "%pip install gradio\n",
        "%pip install evaluate\n",
        "%pip install tensorboard\n",
        "%pip install netron\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD-oYt60h6XS"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh4dUIIfh6XW"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric, Dataset\n",
        "import logging\n",
        "from transformers import BertTokenizer, GPT2Tokenizer, GPT2TokenizerFast, EncoderDecoderModel, Trainer, TrainingArguments, BertTokenizerFast\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import pandas as pd\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, EncoderDecoderModel\n",
        "import types\n",
        "import argparse\n",
        "import logging\n",
        "from functools import partial\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    BertGenerationConfig,\n",
        "    BertGenerationEncoder,\n",
        "    BertTokenizer,\n",
        "    EncoderDecoderModel,\n",
        "    EncoderDecoderConfig,\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2TokenizerFast,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    get_cosine_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "import sacrebleu\n",
        "import random\n",
        "import numpy as np\n",
        "#from tensorboardX import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IzcVohmh6Xb"
      },
      "source": [
        "# **Clear cache**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LtGFLFJh6Xi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq5eeC5Qh6Xl"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3QtMUPih6Xn"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V7X4pvDh6Xr"
      },
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDQpu4rd9cXC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/88kData.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove ID column\n",
        "df = df.drop('ID', axis=1)\n",
        "# remove Null value\n",
        "# df = df.dropna()"
      ],
      "metadata": {
        "id": "gHh0UoVXpGMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NewList = []"
      ],
      "metadata": {
        "id": "_L9tc8IDpOql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# append unneeded fatwa\n",
        "\n",
        "NewList+=list(df[df['ans'].str.contains('انظر إلى الفتوى')].index)\n",
        "NewList+=list(df[df['ans'].str.contains('رقم:')].index)\n",
        "NewList+=list(df[df['ans'].str.contains('فتوى رقم')].index)"
      ],
      "metadata": {
        "id": "pnCZ0jBjpTzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unneeded fatwa\n",
        "df = df.drop(index=NewList, axis=0)"
      ],
      "metadata": {
        "id": "QFvQbbHvpV4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['ans'].str.contains('นู')]"
      ],
      "metadata": {
        "id": "BSFuDQD4pZ5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(index=84488, axis=0)"
      ],
      "metadata": {
        "id": "72XROqA4pcVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No. of new records\n",
        "len(df)"
      ],
      "metadata": {
        "id": "UgaTOEvNpdoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "1srOoruSpveV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_arabic_and_english_numerics(text):\n",
        "    # remove english letter\n",
        "    arabic_pattern = r'[^a-zA-Z\\s0-9]+'\n",
        "    numeric_pattern = r'\\d+'\n",
        "    combined_pattern = f'({arabic_pattern}|{numeric_pattern})'\n",
        "\n",
        "    matches = re.findall(combined_pattern, text)\n",
        "    extracted_text = ' '.join(matches)\n",
        "\n",
        "    return extracted_text"
      ],
      "metadata": {
        "id": "SDrbojlcpg7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Applying the function on the ['ans'] column\n",
        "df['ans'] = df['ans'].apply(extract_arabic_and_english_numerics)\n",
        "df['ans']"
      ],
      "metadata": {
        "id": "ecOv91HypmDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying the function on the ['ques'] column\n",
        "df['ques'] = df['ques'].apply(extract_arabic_and_english_numerics)\n",
        "df['ques']"
      ],
      "metadata": {
        "id": "mOI4dxsUp2un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newlist2 = []"
      ],
      "metadata": {
        "id": "IXUiVC_Up50d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the answers with length less than 118 charachter\n",
        "for k in range(len(df)):\n",
        "\n",
        "    if len(df['ques'].iloc[k]) < 118:\n",
        "        print(df['ques'].iloc[k])"
      ],
      "metadata": {
        "id": "cbqz6m0Tp8_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping every row that contains an answer with length less than 118 charachter\n",
        "for k in range(len(df)):\n",
        "\n",
        "    if len(df['ans'].iloc[k]) < 118:\n",
        "        newlist2.append(k)"
      ],
      "metadata": {
        "id": "tJsawkgYqFe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove from data\n",
        "newlist2 = list(df.iloc[newlist2].index)\n",
        "df = df.drop(index=newlist2, axis=0)"
      ],
      "metadata": {
        "id": "0Gl7Kp_kqGhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making all the dataset columns as a string, and dropping duplicates from the dataset.\n",
        "df = df.astype(str)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "a9P4dNdUqL1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize data to 20000\n",
        "df = df[0:20000]"
      ],
      "metadata": {
        "id": "WlQlMz0cqONV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the cleaned version of the data to the Machine as .csv file\n",
        "df.to_csv(\"Finalized_Data2.csv\",index=False)"
      ],
      "metadata": {
        "id": "gZ2v_wV1qQi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Finalized_Data2.csv\")"
      ],
      "metadata": {
        "id": "2tYlt0-_qSpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zZBWD-6_qbTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"full_text\"]=\" question: \" + df[\"title\"]+df[\"ques\"]+\" answer: \"+df[\"ans\"]"
      ],
      "metadata": {
        "id": "9F1zrZrxqUvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"full_text\"][2]"
      ],
      "metadata": {
        "id": "7g3uEVYBqZTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a-oQfRCP9c6"
      },
      "source": [
        "# **Fetch dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsgG2EF6P9c7"
      },
      "outputs": [],
      "source": [
        "# !wget https://raw.githubusercontent.com/aub-mind/Arabic-Empathetic-Chatbot/master/arabic-empathetic-conversations.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnW-JC7WP9c7"
      },
      "outputs": [],
      "source": [
        "# all_data = load_dataset(\"/content/Arabic-Empathetic-Chatbot/model/ArabicEmpatheticDialogues.py\")\n",
        "\n",
        "\n",
        "all_data = load_dataset('csv', data_files={\"/content/Finalized_Data2.csv\"},delimiter=',', quotechar= '\"')\n",
        "\n",
        "train_dataset = all_data['train'].train_test_split(test_size=0.2,seed=42)['train']\n",
        "val_data = all_data['train'].train_test_split(test_size=0.2,seed=42)['test']\n",
        "val_dataset = val_data.train_test_split(test_size=0.5,seed=42)['train']\n",
        "test_dataset = val_data.train_test_split(test_size=0.5,seed=42)['test']\n",
        "\n",
        "\n",
        "print(\"Length of train data\",len(train_dataset))\n",
        "print(\"Length of dev data\",len(val_dataset))\n",
        "print(\"Length of test data\",len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7W8MVUwvmnC"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Select the first 5 records from the dataset\n",
        "subset = train_dataset.select(range(15))\n",
        "\n",
        "# Define the table headers\n",
        "table = PrettyTable()\n",
        "table.field_names = ['ques', \"ans\"]\n",
        "\n",
        "# Add each record to the table\n",
        "for i in range(len(subset)):\n",
        "    table.add_row([\n",
        "        # subset[i][\"title\"],\n",
        "        subset[i]['ques'],\n",
        "         subset[i]['ans']\n",
        "        # subset[i][\"full_text\"]\n",
        "    ])\n",
        "\n",
        "\n",
        "# Print the table\n",
        "print(table)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz_4VuoDvgjX"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn8P79BBqDb5"
      },
      "outputs": [],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0EFwZ6lqFSl"
      },
      "outputs": [],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVfJ-I_Hh6YS"
      },
      "source": [
        "# **Load Model and Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbI4JsRtP9dB"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = \"asafaya/bert-base-arabic\"\n",
        "model_name2 = \"akhooli/gpt2-small-arabic\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl1KXTh9CgRj"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhkKxCnCh6Ya"
      },
      "outputs": [],
      "source": [
        "\n",
        "#model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name2)\n",
        "#model.to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D1FhTpmh6Yf"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lUu5Wdth6Yf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-6DjbmLP9dG"
      },
      "outputs": [],
      "source": [
        "#set special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "#sensible parameters for beam search\n",
        "#set decoding params\n",
        "model.config.max_length = 128\n",
        "model.config.early_stopping = True\n",
        "\n",
        "model.config.num_beams = 1\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWRXqCD3P9dH"
      },
      "outputs": [],
      "source": [
        "model.base_model.config.encoder.num_hidden_layers = 6\n",
        "model.base_model.config.decoder.num_hidden_layers = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtlHYQfQP9dH"
      },
      "outputs": [],
      "source": [
        "model.tie_weights = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omb_77LJP9dI"
      },
      "source": [
        "# **Save model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaQnUDH9P9dJ"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"bert2gpt-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeyqQNFzAKpU"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"./bert2gpt-model\")\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EysMcNKbh6Yh"
      },
      "source": [
        "# **Evaluator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBz9OQ0QBNzH"
      },
      "outputs": [],
      "source": [
        "from sacrebleu import corpus_bleu\n",
        "def compute_metrics(pred):\n",
        "  labels_ids = pred.label_ids\n",
        "  #pred_ids = torch.argmax(pred.predictions,dim=2)\n",
        "  pred_ids = pred.predictions\n",
        "\n",
        "  # all unnecessary tokens are removed\n",
        "  pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "  labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "  label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "  return {\"bleu\": round(corpus_bleu(pred_str , [label_str]).score, 4)}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t97JcYXkh6Yk"
      },
      "source": [
        "\n",
        "\n",
        "# **Prepare the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K6JZOpdfALu"
      },
      "outputs": [],
      "source": [
        "model.config.max_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import BertConfig, GPT2Config, BertModel, GPT2Model\n",
        "\n",
        "# Load the BERT configuration\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load the GPT2 configuration\n",
        "gpt2_config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Set the decoder_start_token_id attribute in the GPT2 configuration\n",
        "gpt2_config.decoder_start_token_id = \"<cls>\"\n",
        "\n",
        "# Load the BERT and GPT2 models separately\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", config=bert_config)\n",
        "gpt2_model = GPT2Model.from_pretrained(\"gpt2\", config=gpt2_config)"
      ],
      "metadata": {
        "id": "3SVPi1Peynrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v4L2aBJh6Yk"
      },
      "outputs": [],
      "source": [
        "encoder_length = 32\n",
        "decoder_length = 32\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "# map data correctly\n",
        "def map_to_encoder_decoder_inputs(batch):\n",
        "    inputs = tokenizer(batch[\"Question\"], padding=\"max_length\", truncation=True, max_length=encoder_length)\n",
        "    outputs = tokenizer(batch[\"Answer\"], padding=\"max_length\", truncation=True, max_length=decoder_length)\n",
        "\n",
        "    #input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    #attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "    batch[\"labels\"] = outputs.input_ids.copy()\n",
        "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "\n",
        "    \"\"\"\n",
        "    # complicated list comprehension here because pad_token_id alone is not good enough to know whether label should be excluded or not\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if mask == 0 else token for mask, token in mask_and_tokens] for mask_and_tokens in [zip(masks, labels) for masks, labels in zip(batch[\"decoder_attention_mask\"], batch[\"labels\"])]\n",
        "    ]\n",
        "    \"\"\"\n",
        "    assert all([len(x) == encoder_length for x in inputs.input_ids])\n",
        "    assert all([len(x) == decoder_length for x in outputs.input_ids])\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KoXGTZDh6Ym"
      },
      "outputs": [],
      "source": [
        "# make train dataset ready\n",
        "train_data = train_dataset.map(\n",
        "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[ 'ques', 'ans'],)\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4-N5Tyzh6Yn"
      },
      "outputs": [],
      "source": [
        "# same for validation dataset\n",
        "val_data = val_dataset.map(\n",
        "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[ 'ques', 'ans'],\n",
        ")\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGyWK1DOh6Yo"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,\n",
        "                                       max_length=128 , padding=True,\n",
        "                                       model = model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aspCy3etVLey"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvlVESAYh6Yt"
      },
      "outputs": [],
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./bert2gpt-Training\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    num_train_epochs=200,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    fp16=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate = 1e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio = 0.05,\n",
        "    seed = 1995,\n",
        "    save_total_limit = 2,\n",
        "    load_best_model_at_end = True,\n",
        "    #push_to_hub=True,\n",
        "    optim = \"adamw_hf\",\n",
        ")\n",
        "#\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator = data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset =val_data,\n",
        "\n",
        ")\n",
        "#    save_total_limit=3,\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQg03kvx1vve"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyW0x74Qh6Yv"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyfNt8Vxond4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ZOQulGwxbG"
      },
      "source": [
        "# **Copy to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urygn9Slw2tl"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source and destination folders\n",
        "src_folder = '/content/bert2gpt-Training'\n",
        "dst_folder = '/content/drive/MyDrive/bert2-Training'\n",
        "\n",
        "# Copy the folder and its contents to Google Drive\n",
        "shutil.copytree(src_folder, dst_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjzDA4UJVRc3"
      },
      "source": [
        "# **Visualize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhQfjGo_6Y2X"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg-LzePqx2HB"
      },
      "outputs": [],
      "source": [
        "#%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilkGOcUsL1-D"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcKFt_hWx2HI"
      },
      "outputs": [],
      "source": [
        "\n",
        "tensorboard --logdir ./bert2-Training/runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NeM2votkBIo"
      },
      "source": [
        "# **Inference and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqq-HBjkBIo"
      },
      "outputs": [],
      "source": [
        "#model_name = \"bert2gpt-Training\"\n",
        "model_name = \"/content/drive/MyDrive/bert2-Training\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz-K4FYMkBIq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "new_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "new_model.to(\"cuda\")\n",
        "new_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QKTcGZc3uAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaXLsJS2QH8O"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khiElvCjkBI8"
      },
      "outputs": [],
      "source": [
        "# map data correctly\n",
        "def generate_response(context):\n",
        "    inputs = new_tokenizer([context], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = new_model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_response = new_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return output_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxg5rwp8kBI9"
      },
      "outputs": [],
      "source": [
        "input_context = 'ما حكم الخمر'\n",
        "output_response = generate_response(input_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rsKsoSvkBI-"
      },
      "outputs": [],
      "source": [
        "print(output_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOsq1mfwkBJA"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(fn=generate_response, inputs=\"text\", outputs=\"text\",\n",
        "                     title=\"نَوَّرْ\",\n",
        "                     description=\"This is a solution for question answering task\")\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iH5zkcPjVCcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}